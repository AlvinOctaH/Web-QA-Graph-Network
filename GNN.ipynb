{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ALVIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Ensure you have downloaded the required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load data from Excel file\n",
    "try:\n",
    "    data = pd.read_excel(r'C:\\Users\\ALVIN\\Downloads\\Data Chatbot STKI.xlsx')\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found!\")\n",
    "    exit()\n",
    "\n",
    "# Split data into questions and answers\n",
    "questions = data['QUESTION'].tolist()\n",
    "answers = data['ANSWER'].tolist()\n",
    "\n",
    "# Tokenize questions and answers\n",
    "tokens_questions = [word_tokenize(q.lower()) for q in questions]\n",
    "tokens_answers = [word_tokenize(a.lower()) for a in answers]\n",
    "\n",
    "# Create a vocabulary from the dataset\n",
    "vocab = set()\n",
    "for q in tokens_questions:\n",
    "    vocab.update(q)\n",
    "for a in tokens_answers:\n",
    "    vocab.update(a)\n",
    "vocab = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Create a map from tokenized answers to original answers\n",
    "tokenized_to_original_answer = {\" \".join(word_tokenize(a.lower())): a for a in answers}\n",
    "\n",
    "# Define a function to create graph data for a single question-answer pair\n",
    "def create_graph_data(question, answer, vocab):\n",
    "    edge_index = []\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    question_nodes = list(range(len(x), len(x) + len(question)))\n",
    "    answer_nodes = list(range(len(x) + len(question), len(x) + len(question) + len(answer)))\n",
    "\n",
    "    # Create one-hot encoded features for nodes\n",
    "    for w in question:\n",
    "        if w in vocab:\n",
    "            x.append(torch.eye(len(vocab))[vocab[w]])\n",
    "    for w in answer:\n",
    "        if w in vocab:\n",
    "            x.append(torch.eye(len(vocab))[vocab[w]])\n",
    "\n",
    "    # Create edges for question nodes\n",
    "    for i in range(len(question_nodes) - 1):\n",
    "        edge_index.append([question_nodes[i], question_nodes[i + 1]])\n",
    "        edge_index.append([question_nodes[i + 1], question_nodes[i]])\n",
    "\n",
    "    # Create edges for answer nodes\n",
    "    for i in range(len(answer_nodes) - 1):\n",
    "        edge_index.append([answer_nodes[i], answer_nodes[i + 1]])\n",
    "        edge_index.append([answer_nodes[i + 1], answer_nodes[i]])\n",
    "\n",
    "    # Connect the last question node to the first answer node\n",
    "    if question_nodes and answer_nodes:\n",
    "        edge_index.append([question_nodes[-1], answer_nodes[0]])\n",
    "        edge_index.append([answer_nodes[0], question_nodes[-1]])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    if x:  # Ensure x is not empty\n",
    "        x = torch.stack(x)\n",
    "    else:\n",
    "        x = torch.empty((0, len(vocab)))  # Handle case when x is empty\n",
    "\n",
    "    if answer:  # Check if answer is available\n",
    "        original_answer = tokenized_to_original_answer.get(\" \".join(answer), \"\")\n",
    "        y = torch.tensor([answers.index(original_answer)] if original_answer else [-1])  # Use the index of the answer as the label\n",
    "    else:\n",
    "        original_answer = \"\"\n",
    "        y = torch.tensor([-1])  # Set label to -1 if answer is not available\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Create graph data for all question-answer pairs\n",
    "graph_data_list = [create_graph_data(q, a, vocab) for q, a in zip(tokens_questions, tokens_answers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALVIN\\anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.067059984573951\n",
      "Epoch 2/10, Loss: 3.983965658224546\n",
      "Epoch 3/10, Loss: 3.9730625381836524\n",
      "Epoch 4/10, Loss: 3.918081132265238\n",
      "Epoch 5/10, Loss: 3.799857932787675\n",
      "Epoch 6/10, Loss: 3.4244254048054037\n",
      "Epoch 7/10, Loss: 2.9509711746986094\n",
      "Epoch 8/10, Loss: 2.292486616052114\n",
      "Epoch 9/10, Loss: 1.6367898617799466\n",
      "Epoch 10/10, Loss: 1.0331694674319947\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# Define a basic GNN model\n",
    "class BasicGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BasicGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Apply linear transformation and ReLU activation\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Take the mean of node features for graph-level output\n",
    "        x = torch.mean(x, dim=0)\n",
    "        return x\n",
    "\n",
    "# Parameters\n",
    "input_dim = len(vocab)\n",
    "hidden_dim = 64\n",
    "output_dim = len(answers)\n",
    "\n",
    "# Create the model, loss function, and optimizer\n",
    "model = BasicGNN(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create a DataLoader\n",
    "loader = DataLoader(graph_data_list, batch_size=1, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.unsqueeze(0), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(loader)}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: maryamah\n",
      "Predicted Answer: Maryamah is a lecturer and researcher at Data Science Technology, Department of Engineering, Faculty of Advanced Technology and Multidiscipline, Universitas Airlangga.\\nShe received a Bachelor degree from Informatics Engineering, Brawijaya University. Then, Master degree from Institut Teknologi Sepuluh Nopember (Surabaya, Indonesia), majors in Informatics Engineering in 2018. Futhermore, she received a Doctoral degree from Institut Teknologi Sepuluh Nopember with major in Computer Science degree. Her research interests are in Natural Language Processing, Information Retrieval, Big Data, Data Science, Artificial Intelligence, and Optimization. Her current projects related to Natural Language Processing and Information Retrieval.\\nNIK : 199507012022103201\\nNama : Dr. Maryamah, S.Kom.\\n\\nPendidikan : S3 Ilmu Komputer, Institut Teknologi Sepuluh Nopember\\nResearch Interest : Natural Language Processing, Information Retrieval, Big Data, Data Science, Artificial Intelligence, and Optimization\\nEmail : maryamah@ftmm.unair.ac.id\\nGoogle Scholar ID : i5tuzUwAAAAJ\\n\\nScopus ID : 57196236170\\n\\nORCID : 0000-0001-9540-4427\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define a function to preprocess and create graph data for a new question\n",
    "def preprocess_question(question, vocab):\n",
    "    tokens_question = word_tokenize(question.lower())\n",
    "    question_nodes = list(range(len(tokens_question)))\n",
    "    \n",
    "    # Create one-hot encoded features for nodes\n",
    "    x = []\n",
    "    for w in tokens_question:\n",
    "        if w in vocab:\n",
    "            x.append(torch.eye(len(vocab))[vocab[w]])\n",
    "\n",
    "    # Create edges for question nodes\n",
    "    edge_index = []\n",
    "    for i in range(len(question_nodes) - 1):\n",
    "        edge_index.append([question_nodes[i], question_nodes[i + 1]])\n",
    "        edge_index.append([question_nodes[i + 1], question_nodes[i]])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    if x:  # Ensure x is not empty\n",
    "        x = torch.stack(x)\n",
    "    else:\n",
    "        x = torch.empty((0, len(vocab)))  # Handle case when x is empty\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Function to predict the answer for a given question\n",
    "def predict_answer(question, model, vocab, answers):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        graph_data = preprocess_question(question, vocab)\n",
    "        output = model(graph_data)\n",
    "        predicted_index = torch.argmax(output).item()\n",
    "        predicted_answer = answers[predicted_index]\n",
    "    return predicted_answer\n",
    "\n",
    "# Example of using the predict function\n",
    "new_question = \"maryamah\"\n",
    "predicted_answer = predict_answer(new_question, model, vocab, answers)\n",
    "print(f\"Question: {new_question}\")\n",
    "print(f\"Predicted Answer: {predicted_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
